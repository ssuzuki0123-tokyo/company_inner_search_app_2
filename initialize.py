"""
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€æœ€åˆã®ç”»é¢èª­ã¿è¾¼ã¿æ™‚ã«ã®ã¿å®Ÿè¡Œã•ã‚Œã‚‹åˆæœŸåŒ–å‡¦ç†ãŒè¨˜è¿°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚
"""

############################################################
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
############################################################
import os
import logging
from logging.handlers import TimedRotatingFileHandler
from uuid import uuid4
import sys
import unicodedata
from dotenv import load_dotenv
import streamlit as st
from docx import Document
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
import constants as ct
import pandas as pd
from langchain.schema import Document


############################################################
# è¨­å®šé–¢é€£
############################################################
# ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã§å®šç¾©ã—ãŸç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()


############################################################
# é–¢æ•°å®šç¾©
############################################################

def initialize():
    """
    ç”»é¢èª­ã¿è¾¼ã¿æ™‚ã«å®Ÿè¡Œã™ã‚‹åˆæœŸåŒ–å‡¦ç†
    """
    # åˆæœŸåŒ–ãƒ‡ãƒ¼ã‚¿ã®ç”¨æ„
    initialize_session_state()
    # ãƒ­ã‚°å‡ºåŠ›ç”¨ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ
    initialize_session_id()
    # ãƒ­ã‚°å‡ºåŠ›ã®è¨­å®š
    initialize_logger()
    # RAGã®Retrieverã‚’ä½œæˆ
    initialize_retriever()


def initialize_logger():
    """
    ãƒ­ã‚°å‡ºåŠ›ã®è¨­å®š
    """
    # æŒ‡å®šã®ãƒ­ã‚°ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚Œã°èª­ã¿è¾¼ã¿ã€å­˜åœ¨ã—ãªã‘ã‚Œã°æ–°è¦ä½œæˆ
    os.makedirs(ct.LOG_DIR_PATH, exist_ok=True)
    
    # å¼•æ•°ã«æŒ‡å®šã—ãŸåå‰ã®ãƒ­ã‚¬ãƒ¼ï¼ˆãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã‚’å–å¾—
    # å†åº¦åˆ¥ã®ç®‡æ‰€ã§å‘¼ã³å‡ºã—ãŸå ´åˆã€ã™ã§ã«åŒã˜åå‰ã®ãƒ­ã‚¬ãƒ¼ãŒå­˜åœ¨ã—ã¦ã„ã‚Œã°èª­ã¿è¾¼ã‚€
    logger = logging.getLogger(ct.LOGGER_NAME)

    # ã™ã§ã«ãƒ­ã‚¬ãƒ¼ã«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆãƒ­ã‚°ã®å‡ºåŠ›å…ˆã‚’åˆ¶å¾¡ã™ã‚‹ã‚‚ã®ï¼‰ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€åŒã˜ãƒ­ã‚°å‡ºåŠ›ãŒè¤‡æ•°å›è¡Œã‚ã‚Œãªã„ã‚ˆã†å‡¦ç†ã‚’ä¸­æ–­ã™ã‚‹
    if logger.hasHandlers():
        return

    # 1æ—¥å˜ä½ã§ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’ãƒªã‚»ãƒƒãƒˆã—ã€åˆ‡ã‚Šæ›¿ãˆã‚‹è¨­å®š
    log_handler = TimedRotatingFileHandler(
        os.path.join(ct.LOG_DIR_PATH, ct.LOG_FILE),
        when="D",
        encoding="utf8"
    )
    # å‡ºåŠ›ã™ã‚‹ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®šç¾©
    # - ã€Œlevelnameã€: ãƒ­ã‚°ã®é‡è¦åº¦ï¼ˆINFO, WARNING, ERRORãªã©ï¼‰
    # - ã€Œasctimeã€: ãƒ­ã‚°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆã„ã¤è¨˜éŒ²ã•ã‚ŒãŸã‹ï¼‰
    # - ã€Œlinenoã€: ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œç•ªå·
    # - ã€ŒfuncNameã€: ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚ŒãŸé–¢æ•°å
    # - ã€Œsession_idã€: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆèª°ã®ã‚¢ãƒ—ãƒªæ“ä½œã‹åˆ†ã‹ã‚‹ã‚ˆã†ã«ï¼‰
    # - ã€Œmessageã€: ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    formatter = logging.Formatter(
        f"[%(levelname)s] %(asctime)s line %(lineno)s, in %(funcName)s, session_id={st.session_state.session_id}: %(message)s"
    )

    # å®šç¾©ã—ãŸãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã®é©ç”¨
    log_handler.setFormatter(formatter)

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ã€ŒINFOã€ã«è¨­å®š
    logger.setLevel(logging.INFO)

    # ä½œæˆã—ãŸãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆãƒ­ã‚°å‡ºåŠ›å…ˆã‚’åˆ¶å¾¡ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã‚’ã€
    # ãƒ­ã‚¬ãƒ¼ï¼ˆãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®Ÿéš›ã«ç”Ÿæˆã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã«è¿½åŠ ã—ã¦ãƒ­ã‚°å‡ºåŠ›ã®æœ€çµ‚è¨­å®š
    logger.addHandler(log_handler)


def initialize_session_id():
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ä½œæˆ
    """
    if "session_id" not in st.session_state:
        # ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼‰ã‚’ã€ãƒ­ã‚°å‡ºåŠ›ç”¨ã«ä½œæˆ
        st.session_state.session_id = uuid4().hex


def initialize_retriever():
    """
    ç”»é¢èª­ã¿è¾¼ã¿æ™‚ã«RAGã®Retrieverï¼ˆãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‹ã‚‰æ¤œç´¢ã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰ã‚’ä½œæˆ
    """
    # ãƒ­ã‚¬ãƒ¼ã‚’èª­ã¿è¾¼ã‚€ã“ã¨ã§ã€å¾Œç¶šã®å‡¦ç†ä¸­ã«ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼ãªã©ãŒãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²ã•ã‚Œã‚‹
    logger = logging.getLogger(ct.LOGGER_NAME)

    # ã™ã§ã«RetrieverãŒä½œæˆæ¸ˆã¿ã®å ´åˆã€å¾Œç¶šã®å‡¦ç†ã‚’ä¸­æ–­
    if "retriever" in st.session_state:
        return
    
    # RAGã®å‚ç…§å…ˆã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿
    docs_all = load_data_sources()

    # OSãŒWindowsã®å ´åˆã€Unicodeæ­£è¦åŒ–ã¨ã€cp932ï¼ˆWindowsç”¨ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ï¼‰ã§è¡¨ç¾ã§ããªã„æ–‡å­—ã‚’é™¤å»
    for doc in docs_all:
        doc.page_content = adjust_string(doc.page_content)
        for key in doc.metadata:
            doc.metadata[key] = adjust_string(doc.metadata[key])
    
    # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ç”¨æ„
    embeddings = OpenAIEmbeddings()
    
    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ç”¨ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    text_splitter = CharacterTextSplitter(
        chunk_size=ct.CHUNK_SIZE,
        chunk_overlap=ct.CHUNK_OVERLAP,
        separator="\n"
    )

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚’å®Ÿæ–½
    splitted_docs = text_splitter.split_documents(docs_all)

    # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®ä½œæˆ
    db = Chroma.from_documents(splitted_docs, embedding=embeddings)

    # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’æ¤œç´¢ã™ã‚‹Retrieverã®ä½œæˆ
    st.session_state.retriever = db.as_retriever(search_kwargs={"k": ct.VECTOR_SEARCH_TOP_K})


def initialize_session_state():
    """
    åˆæœŸåŒ–ãƒ‡ãƒ¼ã‚¿ã®ç”¨æ„
    """
    if "messages" not in st.session_state:
        # ã€Œè¡¨ç¤ºç”¨ã€ã®ä¼šè©±ãƒ­ã‚°ã‚’é †æ¬¡æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’ç”¨æ„
        st.session_state.messages = []
        # ã€ŒLLMã¨ã®ã‚„ã‚Šã¨ã‚Šç”¨ã€ã®ä¼šè©±ãƒ­ã‚°ã‚’é †æ¬¡æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã‚’ç”¨æ„
        st.session_state.chat_history = []


def load_data_sources():
    """
    RAGã®å‚ç…§å…ˆã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿

    Returns:
        èª­ã¿è¾¼ã‚“ã é€šå¸¸ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
    """
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ ¼ç´ã™ã‚‹ç”¨ã®ãƒªã‚¹ãƒˆ
    docs_all = []
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã®å®Ÿè¡Œï¼ˆæ¸¡ã—ãŸå„ãƒªã‚¹ãƒˆã«ãƒ‡ãƒ¼ã‚¿ãŒæ ¼ç´ã•ã‚Œã‚‹ï¼‰
    recursive_file_check(ct.RAG_TOP_FOLDER_PATH, docs_all)

    web_docs_all = []
    # ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã¯åˆ¥ã«ã€æŒ‡å®šã®Webãƒšãƒ¼ã‚¸å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚‚èª­ã¿è¾¼ã¿
    # èª­ã¿è¾¼ã¿å¯¾è±¡ã®Webãƒšãƒ¼ã‚¸ä¸€è¦§ã«å¯¾ã—ã¦å‡¦ç†
    for web_url in ct.WEB_URL_LOAD_TARGETS:
        # æŒ‡å®šã®Webãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿
        loader = WebBaseLoader(web_url)
        web_docs = loader.load()
        # foræ–‡ã®å¤–ã®ãƒªã‚¹ãƒˆã«èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
        web_docs_all.extend(web_docs)
    # é€šå¸¸èª­ã¿è¾¼ã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«Webãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    docs_all.extend(web_docs_all)

    return docs_all


def recursive_file_check(path, docs_all):
    """
    RAGã®å‚ç…§å…ˆã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿

    Args:
        path: èª­ã¿è¾¼ã¿å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹
        docs_all: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ ¼ç´ã™ã‚‹ç”¨ã®ãƒªã‚¹ãƒˆ
    """
    # ãƒ‘ã‚¹ãŒãƒ•ã‚©ãƒ«ãƒ€ã‹ã©ã†ã‹ã‚’ç¢ºèª
    if os.path.isdir(path):
        # ãƒ•ã‚©ãƒ«ãƒ€ã®å ´åˆã€ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€åã®ä¸€è¦§ã‚’å–å¾—
        files = os.listdir(path)
        # å„ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€ã«å¯¾ã—ã¦å‡¦ç†
        for file in files:
            # ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€åã ã‘ã§ãªãã€ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
            full_path = os.path.join(path, file)
            # ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’æ¸¡ã—ã€å†å¸°çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã®é–¢æ•°ã‚’å®Ÿè¡Œ
            recursive_file_check(full_path, docs_all)
    else:
        # ãƒ‘ã‚¹ãŒãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        file_load(path, docs_all)

def csv_single_doc_load(path, encoding="utf-8"):
    """
    CSVå…¨è¡Œã‚’â€œéƒ¨é–€ã”ã¨ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³â€ã«ã¾ã¨ã‚ã¦ã€1ã¤ã®Documentã¨ã—ã¦è¿”ã™ãƒ­ãƒ¼ãƒ€ãƒ¼
    - è¦‹å‡ºã—ã«åŒç¾©èªã‚’ä½µè¨˜ï¼ˆäººäº‹éƒ¨/HR/Human Resources/ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒªã‚½ãƒ¼ã‚¹ï¼‰
    - å„å¾“æ¥­å“¡ã¯ [EMP] ã§åŒºåˆ‡ã‚Šã€ã‚­ãƒ¼:ãƒãƒªãƒ¥ãƒ¼å½¢å¼ã«æ•´å½¢
    """
    df = pd.read_csv(path, encoding=encoding)

    COL_ID        = "ç¤¾å“¡ID"
    COL_NAME      = "æ°åï¼ˆãƒ•ãƒ«ãƒãƒ¼ãƒ ï¼‰"
    COL_SEX       = "æ€§åˆ¥"
    COL_BIRTH     = "ç”Ÿå¹´æœˆæ—¥"
    COL_AGE       = "å¹´é½¢"
    COL_MAIL      = "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"
    COL_EMP_CLASS = "å¾“æ¥­å“¡åŒºåˆ†"
    COL_JOINED    = "å…¥ç¤¾æ—¥"
    COL_DEPT      = "éƒ¨ç½²"
    COL_ROLE      = "å½¹è·"
    COL_SKILLS    = "ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ"
    COL_CERTS     = "ä¿æœ‰è³‡æ ¼"
    COL_UNIV      = "å¤§å­¦å"
    COL_FACULTY   = "å­¦éƒ¨ãƒ»å­¦ç§‘"
    COL_GRAD      = "å’æ¥­å¹´æœˆæ—¥"

    def dept_header_with_synonyms(dept):
        synonyms = []
        if dept == "äººäº‹éƒ¨":
            synonyms = ["HR", "Human Resources", "ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒªã‚½ãƒ¼ã‚¹"]
        elif dept == "å–¶æ¥­éƒ¨":
            synonyms = ["Sales", "ã‚»ãƒ¼ãƒ«ã‚¹"]
        elif dept == "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°éƒ¨":
            synonyms = ["Marketing", "ãƒãƒ¼ãƒ†ã‚£ãƒ³ã‚°", "ãƒãƒ¼ã‚±"]
        elif dept == "ç·å‹™éƒ¨":
            synonyms = ["General Affairs", "GA", "ã‚¼ãƒãƒ©ãƒ«ã‚¢ãƒ•ã‚§ã‚¢ãƒ¼ã‚º"]
        elif dept == "çµŒç†éƒ¨":
            synonyms = ["Accounting", "Finance", "ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹"]
        elif dept == "ITéƒ¨":
            synonyms = ["IT", "ã‚¤ãƒ³ãƒ•ã‚©ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "ã‚·ã‚¹ãƒ†ãƒ éƒ¨", "æƒ…ã‚·ã‚¹"]
        return f"## éƒ¨ç½²: {dept}" + ((" | " + " | ".join(synonyms)) if synonyms else "")

    parts = []
    print(f"\nğŸ” CSVå‡¦ç†é–‹å§‹: {path}")
    print(f"DataFrameå½¢çŠ¶: {df.shape}")
    print(f"éƒ¨ç½²ä¸€è¦§: {df[COL_DEPT].unique().tolist()}")
    
    for dept, g in df.groupby(COL_DEPT):
        print(f"\nğŸ“ éƒ¨ç½²å‡¦ç†ä¸­: {dept} ({len(g)}å)")
        parts.append("\n")
        parts.append(dept_header_with_synonyms(dept))

        g_sorted = g.sort_values(by=[COL_NAME, COL_ID], kind="stable")

        for i, (_, row) in enumerate(g_sorted.iterrows(), 1):
            print(f"  ğŸ‘¤ å¾“æ¥­å“¡ {i}/{len(g)}: {row[COL_NAME]} ({row[COL_ID]})")
            emp_block = (
                "[EMP]"
                f"ç¤¾å“¡ID: {row[COL_ID]},"
                f"æ°åï¼ˆãƒ•ãƒ«ãƒãƒ¼ãƒ ï¼‰: {row[COL_NAME]},"
                f"æ€§åˆ¥: {row[COL_SEX]},"
                f"ç”Ÿå¹´æœˆæ—¥: {row[COL_BIRTH]},"
                f"å¹´é½¢: {row[COL_AGE]},"
                f"ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹: {row[COL_MAIL]},"
                f"å¾“æ¥­å“¡åŒºåˆ†: {row[COL_EMP_CLASS]},"
                f"å…¥ç¤¾æ—¥: {row[COL_JOINED]},"
                f"éƒ¨ç½²: {row[COL_DEPT]},"
                f"å½¹è·: {row[COL_ROLE]},"
                f"ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: {row[COL_SKILLS]},"
                f"ä¿æœ‰è³‡æ ¼: {row[COL_CERTS]},"
                f"å¤§å­¦å: {row[COL_UNIV]},"
                f"å­¦éƒ¨ãƒ»å­¦ç§‘: {row[COL_FACULTY]},"
                f"å’æ¥­å¹´æœˆæ—¥: {row[COL_GRAD]},"
            )
            parts.append(emp_block)
            
    
    full_text = "#".join(parts).strip()
    
    # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«full_textã®å†…å®¹ã‚’è¡¨ç¤º
    print("=" * 60)
    print("CSVå‡¦ç†çµæœ - full_text ã®å†…å®¹:")
    print("=" * 60)
    print(full_text)
    print("=" * 60)
    print(f"full_text ã®æ–‡å­—æ•°: {len(full_text)}")
    print("=" * 60)
    
    return [Document(page_content=full_text, metadata={"source": path, "type": "csv"})]

def file_load(path, docs_all):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

    Args:
        path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        docs_all: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ ¼ç´ã™ã‚‹ç”¨ã®ãƒªã‚¹ãƒˆ
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’å–å¾—
    file_extension = os.path.splitext(path)[1]
    # ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ‹¡å¼µå­ã‚’å«ã‚€ï¼‰ã‚’å–å¾—
    file_name = os.path.basename(path)

    # æƒ³å®šã—ã¦ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®å ´åˆã®ã¿èª­ã¿è¾¼ã‚€
    if file_extension in ct.SUPPORTED_EXTENSIONS:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã«åˆã£ãŸdata loaderã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if file_extension == ".csv":
            docs = csv_single_doc_load(path, encoding="utf-8")
        else:
            loader = ct.SUPPORTED_EXTENSIONS[file_extension](path)
            docs = loader.load()
        
        docs_all.extend(docs)


def adjust_string(s):
    """
    Windowsç’°å¢ƒã§RAGãŒæ­£å¸¸å‹•ä½œã™ã‚‹ã‚ˆã†èª¿æ•´
    
    Args:
        s: èª¿æ•´ã‚’è¡Œã†æ–‡å­—åˆ—
    
    Returns:
        èª¿æ•´ã‚’è¡Œã£ãŸæ–‡å­—åˆ—
    """
    # èª¿æ•´å¯¾è±¡ã¯æ–‡å­—åˆ—ã®ã¿
    if type(s) is not str:
        return s

    # OSãŒWindowsã®å ´åˆã€Unicodeæ­£è¦åŒ–ã¨ã€cp932ï¼ˆWindowsç”¨ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ï¼‰ã§è¡¨ç¾ã§ããªã„æ–‡å­—ã‚’é™¤å»
    if sys.platform.startswith("win"):
        s = unicodedata.normalize('NFC', s)
        s = s.encode("cp932", "ignore").decode("cp932")
        return s
    
    # OSãŒWindowsä»¥å¤–ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
    return 